{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_multi_img_with_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x7MQixkIMKM"
      },
      "source": [
        "# CNN을 통한 다중 이미지 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QQOaOx2ISqq"
      },
      "source": [
        "## Google Colab 링크\n",
        "\n",
        "https://colab.research.google.com/drive/1GcJCFBzVJS-zfe-3XAdXauxXtVHPsdmQ#scrollTo=7QQOaOx2ISqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoatHnYKI8pK"
      },
      "source": [
        "**학습 데이터세트는 AI Hub에서 신청하여 받았고, 저작자는 한국지능정보사회진흥원이다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEmmauQdIX_g"
      },
      "source": [
        "## 참고자료"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tL3u_nwIclv"
      },
      "source": [
        "https://lsjsj92.tistory.com/387"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GknSALBMJB9e"
      },
      "source": [
        "# Google Colab 재시작\n",
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0xozfumIjB8"
      },
      "source": [
        "## 데이터세트 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGtfA_LdIyde"
      },
      "source": [
        "구글 드라이브에 업로드한 zip 파일을 File ID로 다운받고 압축을 해제한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rCuKfnCIm7A",
        "outputId": "b93b8b28-174c-4409-e739-945342f9ae6f"
      },
      "source": [
        "# !gdown --id 1AeNCnN8nOQI2q3p7kpeht2y6Aa95eHmT --output other_food.zip\n",
        "!gdown --id 14vWvDRXxyCbtbh8-fCPfYGMbBC53b_A0 --output other_food.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14vWvDRXxyCbtbh8-fCPfYGMbBC53b_A0\n",
            "To: /content/other_food.zip\n",
            "348MB [00:04, 78.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2QPAQNnL6-b",
        "outputId": "2b04a021-5436-4ce0-a955-eb1e60717e27"
      },
      "source": [
        "!gdown --id 12cWI3H7aDypQhBIlhZh0_azL_G7k4ujS --output img_test.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12cWI3H7aDypQhBIlhZh0_azL_G7k4ujS\n",
            "To: /content/img_test.zip\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\r100% 1.90M/1.90M [00:00<00:00, 30.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quvn8e64MCL4"
      },
      "source": [
        "`other_food`는 훈련 데이터, `img_test`는 검증 데이터다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHD_iCiZL6CH"
      },
      "source": [
        "!unzip other_food.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TJppBKVIqqE"
      },
      "source": [
        "!unzip img_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC8WERctIpqu"
      },
      "source": [
        "경로를 지정하고 데이터세트 이미지 개수를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ees9EGzDIy_w"
      },
      "source": [
        "import pathlib\n",
        "img_dir = 'other_food'\n",
        "data_dir = pathlib.Path(img_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkEgbRQnI0mc",
        "outputId": "424bf19b-7cc5-4636-f17a-6585ad9c12bb"
      },
      "source": [
        "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "image_list = list(data_dir.glob('*/*.jpg'))\n",
        "image_list.extend(list(data_dir.glob('*/*.jpeg')))\n",
        "image_list.extend(list(data_dir.glob('*/*.png')))\n",
        "image_list.extend(list(data_dir.glob('*/*.gif')))\n",
        "image_count = len(image_list)\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfJQFQ1zJVnc"
      },
      "source": [
        "## 멀티라벨 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBqWWHTYKwVF"
      },
      "source": [
        "데이터세트를 `콩자반`, `피자`, `후라이드치킨` 3가지로 분류한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwQwSuKDJtkp"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t01Mc4xPgK8i"
      },
      "source": [
        "하위 폴더 경로를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMLASO7kfd56",
        "outputId": "7f504b76-2cef-47ec-e162-bfdd2fcac039"
      },
      "source": [
        "test_for_categories_list = glob.glob(\"other_food/*/\")\n",
        "print(test_for_categories_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['other_food/후라이드치킨/', 'other_food/피자/', 'other_food/콩자반/']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpj6bXM2wHc"
      },
      "source": [
        "폴더 경로에서 음식 이름을 추출하여 카테고리 배열로 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edfp1t9x28Pu",
        "outputId": "ddb2696e-c6a6-4e7c-a454-ee561e1fd500"
      },
      "source": [
        "categories = []\n",
        "for food_dir in test_for_categories_list:\n",
        "    food = food_dir[11:-1]\n",
        "    categories.append(food)\n",
        "\n",
        "print(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['후라이드치킨', '피자', '콩자반']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7EDawBloXHF",
        "outputId": "72e133a4-3fc4-4c21-aee6-42b3e69b7efe"
      },
      "source": [
        "# test for making categoires with sub folder name\n",
        "caltech_dir = \"other_food\"\n",
        "nb_classes = len(test_for_categories_list)\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, food_dir in enumerate(test_for_categories_list):\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    food = food_dir[11:-1]\n",
        "    print(food)\n",
        "\n",
        "    image_dir = caltech_dir + \"/\" + food\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    files.extend(glob.glob(image_dir+'/*.jpeg'))\n",
        "    files.extend(glob.glob(image_dir+'/*.png'))\n",
        "    files.extend(glob.glob(image_dir+'/*.gif'))\n",
        "    print(food, \" 파일 길이 : \", len(files))\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(food, \" : \", f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "후라이드치킨\n",
            "후라이드치킨  파일 길이 :  991\n",
            "후라이드치킨  :  other_food/후라이드치킨/Img_028_0790.jpg\n",
            "후라이드치킨  :  other_food/후라이드치킨/Img_028_0691.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "콩자반\n",
            "콩자반  파일 길이 :  986\n",
            "콩자반  :  other_food/콩자반/Img_025_0825.jpg\n",
            "콩자반  :  other_food/콩자반/Img_025_0889.jpg\n",
            "피자\n",
            "피자  파일 길이 :  1000\n",
            "피자  :  other_food/피자/Img_027_0536.jpg\n",
            "피자  :  other_food/피자/Img_027_0832.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGkoiQUnJuKY",
        "outputId": "97099afb-9d3b-4a75-a48a-1af46461ec7c"
      },
      "source": [
        "caltech_dir = \"other_food\"\n",
        "# categories = ['beans', 'pizzas', 'fried_chickens']\n",
        "nb_classes = len(categories)\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, food in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"/\" + food\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    files.extend(glob.glob(image_dir+'/*.jpeg'))\n",
        "    files.extend(glob.glob(image_dir+'/*.png'))\n",
        "    files.extend(glob.glob(image_dir+'/*.gif'))\n",
        "    print(food, \" 파일 길이 : \", len(files))\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(food, \" : \", f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "후라이드치킨  파일 길이 :  991\n",
            "후라이드치킨  :  other_food/후라이드치킨/Img_028_0668.jpg\n",
            "후라이드치킨  :  other_food/후라이드치킨/Img_028_0227.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "피자  파일 길이 :  1000\n",
            "피자  :  other_food/피자/Img_027_0000.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "피자  :  other_food/피자/Img_027_0798.jpg\n",
            "콩자반  파일 길이 :  986\n",
            "콩자반  :  other_food/콩자반/Img_025_0701.jpg\n",
            "콩자반  :  other_food/콩자반/Img_025_0347.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d29CxCTbKIfy"
      },
      "source": [
        "!mkdir numpy_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j4ILhO8KIIw",
        "outputId": "a3073d70-70ee-4093-e2eb-80fb46d090ae"
      },
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#1 0 0 0 이면 airplanes\n",
        "#0 1 0 0 이면 buddha 이런식\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"numpy_data/multi_image_data.npy\", xy)\n",
        "\n",
        "print(\"ok\", len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok 2977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgVY1w9MKXN-"
      },
      "source": [
        "## 모델 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hwG9mRDKYyM"
      },
      "source": [
        "이제 numpy 데이터를 불러와 훈련을 시작한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6MibNOGKfr-"
      },
      "source": [
        "import os, glob, numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssWsJb2KggD",
        "outputId": "a22d6007-0a9b-40e5-97cd-b8d22bce71b3"
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)\n",
        "\n",
        "X_train, X_test, y_train, y_test = np.load('numpy_data/multi_image_data.npy', allow_pickle=True)\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2232, 64, 64, 3)\n",
            "2232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYBL7CwTK8vI"
      },
      "source": [
        "# categories = ['beans', 'pizzas', 'fried_chickens']\n",
        "# nb_classes = len(categories)\n",
        "\n",
        "#일반화\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZLjS5YCLEa4"
      },
      "source": [
        "!mkdir model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPq6cAkCK_uJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_dir = 'model'\n",
        "    \n",
        "if not os.path.exists(model_dir):\n",
        "    os.mkdir(model_dir)\n",
        "    \n",
        "model_path = model_dir + '/multi_img_classification.model'\n",
        "checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JopavN_PLKRO",
        "outputId": "6c9d212e-9a44-45fa-c42e-b8d9d71190c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               4194560   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 4,214,723\n",
            "Trainable params: 4,214,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyKNyc_WLM4f",
        "outputId": "bbcbd72c-19e6-46c8-ec4a-9ac043670208"
      },
      "source": [
        "#데이터셋이 적어서 validation을 그냥 test 데이터로 했습니다. \n",
        "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\n",
        "# history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - 34s 19ms/step - loss: 1.4043 - accuracy: 0.4874 - val_loss: 0.5454 - val_accuracy: 0.6801\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.54543, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.7594 - val_loss: 0.3940 - val_accuracy: 0.8546\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.54543 to 0.39402, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8315 - val_loss: 0.3608 - val_accuracy: 0.8680\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.39402 to 0.36077, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.3408 - accuracy: 0.8592 - val_loss: 0.3301 - val_accuracy: 0.8725\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.36077 to 0.33013, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.2951 - accuracy: 0.8854 - val_loss: 0.2965 - val_accuracy: 0.8837\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.33013 to 0.29652, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.2480 - accuracy: 0.9065 - val_loss: 0.2606 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.29652 to 0.26055, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.2416 - accuracy: 0.8992 - val_loss: 0.2651 - val_accuracy: 0.9060\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.26055\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.9363 - val_loss: 0.2942 - val_accuracy: 0.9060\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.26055\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.9324 - val_loss: 0.2350 - val_accuracy: 0.9150\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.26055 to 0.23503, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9541 - val_loss: 0.3189 - val_accuracy: 0.8747\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.23503\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1823 - accuracy: 0.9303 - val_loss: 0.2222 - val_accuracy: 0.9150\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.23503 to 0.22224, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1032 - accuracy: 0.9607 - val_loss: 0.2630 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.22224\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9631 - val_loss: 0.3358 - val_accuracy: 0.8725\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.22224\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0937 - accuracy: 0.9627 - val_loss: 0.2242 - val_accuracy: 0.9195\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.22224\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9612 - val_loss: 0.2023 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.22224 to 0.20230, saving model to model/multi_img_classification.model\n",
            "INFO:tensorflow:Assets written to: model/multi_img_classification.model/assets\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9803 - val_loss: 0.2258 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.20230\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.2239 - val_accuracy: 0.9351\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.20230\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9735 - val_loss: 0.3049 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.20230\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9805 - val_loss: 0.2221 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.20230\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9877 - val_loss: 0.2436 - val_accuracy: 0.9195\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.20230\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.2346 - val_accuracy: 0.9239\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.20230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg3PRGM-LR6d",
        "outputId": "9613dbc8-c04b-42bb-b0d2-2922da267093"
      },
      "source": [
        "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 6ms/step - loss: 0.2790 - accuracy: 0.9181\n",
            "정확도 : 0.9181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Hc1x4uGyLT9C",
        "outputId": "4935ff7a-5259-4f24-9e2d-9ceb2356dfb3"
      },
      "source": [
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YpIs24ZK-36"
      },
      "source": [
        "## 모델 정확성 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eSgQKAHMZrF"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfi9HxyKMfzN",
        "outputId": "8ffe250b-269d-4a29-8bb2-c178cbb9ed10"
      },
      "source": [
        "caltech_dir = \"img_test\"\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(caltech_dir+\"/*.*\")\n",
        "for i, f in enumerate(files):\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "model = load_model('model/multi_img_classification.model')\n",
        "\n",
        "prediction = model.predict(X)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "cnt = 0\n",
        "\n",
        "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
        "for i in prediction:\n",
        "    pre_ans = i.argmax()  # 예측 레이블\n",
        "    print(i)\n",
        "    print(pre_ans)\n",
        "\n",
        "    # pre_ans_str = ''\n",
        "    # if pre_ans == 0: pre_ans_str = \"후라이드치킨\"\n",
        "    # elif pre_ans == 1: pre_ans_str = \"콩자반\"\n",
        "    # else: pre_ans_str = \"피자\"\n",
        "\n",
        "    pre_ans_str = categories[pre_ans]\n",
        "    print(\"해당 \"+filenames[cnt].split(\"/\")[1]+\" 이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "\n",
        "    # if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"/\")[1]+\" 이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "    # if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"/\")[1]+\" 이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
        "    # if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"/\")[1]+\" 이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "    # print(i[0], i[1], i[2])\n",
        "    cnt += 1\n",
        "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
        "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
        "    # 이걸 한 것은 _4.py에."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.000 0.000 1.000]\n",
            "2\n",
            "해당 beans_0002.png 이미지는 콩자반로 추정됩니다.\n",
            "[1.000 0.000 0.000]\n",
            "0\n",
            "해당 fried_chickens_0000.jpg 이미지는 후라이드치킨로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 beans_0000.jpg 이미지는 피자로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 fried_chickens_0001.jpg 이미지는 피자로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 pizzas_0002.jpg 이미지는 피자로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 pizzas_0000.jpg 이미지는 피자로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 fried_chickens_0002.jpg 이미지는 피자로 추정됩니다.\n",
            "[0.000 0.000 1.000]\n",
            "2\n",
            "해당 beans_0001.jpg 이미지는 콩자반로 추정됩니다.\n",
            "[0.000 1.000 0.000]\n",
            "1\n",
            "해당 pizzas_0001.jpg 이미지는 피자로 추정됩니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssx-Pc72bJ0r"
      },
      "source": [
        "## 모델 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYC57Z62c3Si"
      },
      "source": [
        "먼저 하위 폴더 목록을 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao-BxDaMbM0p",
        "outputId": "4b73c4e5-240b-4eec-b63a-7c5434fba372"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimg_test\u001b[0m/     \u001b[01;34mmodel\u001b[0m/       \u001b[01;34mother_food\u001b[0m/     \u001b[01;34msample_data\u001b[0m/\n",
            "img_test.zip  \u001b[01;34mnumpy_data\u001b[0m/  other_food.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUnx3AJCc3A1"
      },
      "source": [
        "다음 다운로드 할 모델 폴더를 압축한다. `model` 폴더 하위에 `myModel.zip` 파일이 생성된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZhp6eAGbWx7"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        " \n",
        "new_zips= zipfile.ZipFile('/content/model/myModel.zip', 'w')\n",
        " \n",
        "for folder, subfolders, files in os.walk('/content/model/'):\n",
        " \n",
        "    for file in files:\n",
        "        new_zips.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), '/content/model/'), compress_type = zipfile.ZIP_DEFLATED)\n",
        " \n",
        "new_zips.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjn9CW0_dI6P"
      },
      "source": [
        "마지막으로 생성한 zip 파일을 로컬 PC에 다운받는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4Tbm394JdJvD",
        "outputId": "cbbce47b-5906-4a9c-b5b0-20d20f4e2432"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/model/myModel.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_99dfbf99-8d5c-4255-80c8-3b155fb6df9a\", \"myModel.zip\", 37965838)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia91k0Tidywn"
      },
      "source": [
        "다운받은 모델을 다른 프로젝트에서 사용할 때에는 현 프로젝트처럼 압축을 풀고 폴더로 로드해야 한다.\n",
        "\n",
        "실제로 다운받은 파일 압축을 풀어보니 깨진 myModel.zip 파일이 하나 더 들어있었다.\n",
        "\n",
        "그 외의 파일들은 다 제대로 들어있다."
      ]
    }
  ]
}